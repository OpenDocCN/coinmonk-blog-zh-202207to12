<html>
<head>
<title>Of Collaborations, Gossips, and a Masking Trick</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">合作、流言蜚语和伪装技巧</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/of-collaborations-gossips-and-a-masking-trick-e7af3d9730ea?source=collection_archive---------13-----------------------#2022-08-13">https://medium.com/coinmonks/of-collaborations-gossips-and-a-masking-trick-e7af3d9730ea?source=collection_archive---------13-----------------------#2022-08-13</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><h2 id="798b" class="hr hs ht bd b gc hu hv hw hx hy hz ek ia translated" aria-label="kicker paragraph">高级人工智能</h2><div class=""/><div class=""><h2 id="bfe7" class="pw-subtitle-paragraph iz ic ht bd b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ek translated">联邦学习对ML的作用会像区块链对DeFi的作用一样吗？</h2></div><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff jr"><img src="../Images/a88a4cefa4bbcead5237326ba51a8d0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_qEoGuq3iB4GsswrFLMLRg.jpeg"/></div></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek">Image by <a class="ae kh" href="https://unsplash.com/@hajjidirir?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Ismail Salad Osman Hajji dirir</a> on <a class="ae kh" href="https://unsplash.com/s/photos/federated-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="948e" class="pw-post-body-paragraph ki kj ht kk b kl km jd kn ko kp jg kq kr ks kt ku kv kw kx ky kz la lb lc ld hm dt translated">对数据隐私的日益关注，加上对分散众包平台的日益关注，引发了对设备上机器学习的需求。在本文中，我们将讨论联合学习，这是一种<strong class="kk id"> <em class="le">协作机器学习方法，它在不交换用户原始数据</em> </strong>的情况下运行。</p><h1 id="17ae" class="lf lg ht bd lh li lj lk ll lm ln lo lp ji lq jj lr jl ls jm lt jo lu jp lv lw dt translated">什么是联合学习？</h1><p id="8c02" class="pw-post-body-paragraph ki kj ht kk b kl lx jd kn ko ly jg kq kr lz kt ku kv ma kx ky kz mb lb lc ld hm dt translated">联邦学习(FL)是一种机器学习方法，能够在<strong class="kk id"><em class="le"/></strong>分散的局部数据集上训练<strong class="kk id"><em class="le"/></strong>。</p><p id="00a3" class="pw-post-body-paragraph ki kj ht kk b kl km jd kn ko kp jg kq kr ks kt ku kv kw kx ky kz la lb lc ld hm dt translated">FL旨在利用多个参与者的优势，这些参与者可以单独为一项全球任务做出贡献。参与者可以是连接到互联网、生成用户交互数据并具有足够处理能力的任何计算设备。</p><h1 id="2590" class="lf lg ht bd lh li lj lk ll lm ln lo lp ji lq jj lr jl ls jm lt jo lu jp lv lw dt translated">为什么现在逃跑？</h1><p id="e2dd" class="pw-post-body-paragraph ki kj ht kk b kl lx jd kn ko ly jg kq kr lz kt ku kv ma kx ky kz mb lb lc ld hm dt translated">在移动计算中，用户要求快速响应，而用户设备和中央服务器之间的通信时间对于良好的用户体验来说可能太慢。为了克服这一点，可以将模型放置在终端用户设备中。但是，由于终端用户设备无法访问完整的数据，因此持续学习成为一项挑战。</p><p id="849b" class="pw-post-body-paragraph ki kj ht kk b kl km jd kn ko kp jg kq kr ks kt ku kv kw kx ky kz la lb lc ld hm dt translated">FL通过在边缘设备上实现持续学习，同时确保最终用户数据不会离开最终用户设备，从而克服了这一挑战。这允许个人数据保留在本地站点，降低了个人数据泄露的可能性。</p><p id="190e" class="pw-post-body-paragraph ki kj ht kk b kl km jd kn ko kp jg kq kr ks kt ku kv kw kx ky kz la lb lc ld hm dt translated">即使在数据源不共享数据的情况下，FL也有助于访问更丰富和多样化的数据，这可以改进模型。此外，由于FL模型不需要一个复杂的中央服务器来分析数据，因此提高了硬件效率。</p><h2 id="7064" class="mc lg ht bd lh md me mf ll mg mh mi lp kr mj mk lr kv ml mm lt kz mn mo lv hz dt translated">少数使用案例</h2><p id="3b76" class="pw-post-body-paragraph ki kj ht kk b kl lx jd kn ko ly jg kq kr lz kt ku kv ma kx ky kz mb lb lc ld hm dt translated">像谷歌这样的公司在其智能手机键盘上使用FL技术来预测下一个单词。苹果的FL技术利用了用户交互历史，与现场A/B实验相比，大大减少了周转时间。医疗保健和健康保险行业可以利用FL，因为它允许保护原始源中的敏感数据。在自动驾驶汽车中，FL可以更好地实现实时决策和持续学习，并允许模型随着时间的推移根据不同车辆的输入进行改进。</p><h1 id="3b56" class="lf lg ht bd lh li lj lk ll lm ln lo lp ji lq jj lr jl ls jm lt jo lu jp lv lw dt translated">它是如何工作的？</h1><p id="1e48" class="pw-post-body-paragraph ki kj ht kk b kl lx jd kn ko ly jg kq kr lz kt ku kv ma kx ky kz mb lb lc ld hm dt translated">在FL中，数据永远不会离开用户的设备。使用设备的计算能力和数据，在本地进行ML模型的训练。只有来自本地训练模型的训练元信息(权重和偏差)被传送到中央服务器。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mp"><img src="../Images/8e43ab8dfe21150920dc97ba6cb3bbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dU23HjgyYEjMAzLeKV_oXw.png"/></div></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek">Image Source: <a class="ae kh" href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" rel="noopener ugc nofollow" target="_blank">Google AI</a></figcaption></figure><p id="1836" class="pw-post-body-paragraph ki kj ht kk b kl km jd kn ko kp jg kq kr ks kt ku kv kw kx ky kz la lb lc ld hm dt translated">该算法基于特定的试探法从候选人池中选择合格参与者的子集，以便最小化本地培训可能对用户体验产生的负面影响。合格设备组中的每个参与者都会收到一份全局或训练模型。然后，每个设备使用本地数据开始训练模型的本地微调过程。在训练之后，来自每个本地模型的更新参数被发送到中央服务器用于全局更新。当从客户端移动到服务器时，该训练元数据被加密，并且服务器仅解密聚集的训练结果，因此在该步骤中，没有逆向工程可以泄露关于单个客户端的数据的信息。最后，服务器汇总所有客户端的更新，并开始新一轮更新。</p><h2 id="8159" class="mc lg ht bd lh md me mf ll mg mh mi lp kr mj mk lr kv ml mm lt kz mn mo lv hz dt translated">零和掩蔽</h2><p id="68a2" class="pw-post-body-paragraph ki kj ht kk b kl lx jd kn ko ly jg kq kr lz kt ku kv ma kx ky kz mb lb lc ld hm dt translated">这种函数加密被称为零和掩蔽协议。零和掩码在一个方向上的总和为1，在另一个方向上的总和为0。其中一个组合并保护加密的或安全的用户数据，而下一个将训练结果解密给服务器。这个过程一直持续到完成，然后掩模彼此抵消。以下是关于FL的几点注意事项:</p><ul class=""><li id="91bc" class="mq mr ht kk b kl km ko kp kr ms kv mt kz mu ld mv mw mx my dt translated">大多数最大似然算法假设数据是IID(独立同分布)。然而，在FL的情况下，由于每个参与者仅持有来自其自身使用的数据，我们不能假设每个数据部分(来自每个客户端设备)代表整个群体。</li><li id="3bef" class="mq mr ht kk b kl mz ko na kr nb kv nc kz nd ld mv mw mx my dt translated">FL最适用于设备上的数据比服务器上的数据更相关的情况。在今天这个高度个性化的世界里，这种情况经常发生。</li><li id="ae5e" class="mq mr ht kk b kl mz ko na kr nb kv nc kz nd ld mv mw mx my dt translated">FL的分布式测试带来了在最重要的地方测试新版本模型的好处，也就是在用户的设备上。因为服务器不能访问训练数据，所以在使用客户端的贡献更新组合模型之后，它不能测试组合模型。因此，培训和测试在用户的设备上进行。</li></ul><h2 id="08ea" class="mc lg ht bd lh md me mf ll mg mh mi lp kr mj mk lr kv ml mm lt kz mn mo lv hz dt translated">履行</h2><blockquote class="ne nf ng"><p id="85d4" class="ki kj le kk b kl km jd kn ko kp jg kq nh ks kt ku ni kw kx ky nj la lb lc ld hm dt translated">FL已经可以在tensorflow-federated-nightly下使用。</p></blockquote><p id="d1f4" class="pw-post-body-paragraph ki kj ht kk b kl km jd kn ko kp jg kq kr ks kt ku kv kw kx ky kz la lb lc ld hm dt translated">下面是为涉及3个类的分类任务构建超简单FL模型的说明性代码片段。</p><pre class="js jt ju jv fq nk nl nm nn aw no dt"><span id="a513" class="mc lg ht nl b fv np nq l nr ns">!pip install --quiet --upgrade tensorflow-federated-nightly</span><span id="9702" class="mc lg ht nl b fv nt nq l nr ns">import numpy as np<br/>np.random.seed(0)</span><span id="a564" class="mc lg ht nl b fv nt nq l nr ns">import tensorflow as tf<br/>import tensorflow_federated as tff</span><span id="f5ce" class="mc lg ht nl b fv nt nq l nr ns">def create_model(num_classes:int):<br/>    model = tf.keras.models.Sequential([<br/>        tf.keras.layers.InputLayer(input_shape=(784,)),<br/>        tf.keras.layers.Dense(num_classes),<br/>        tf.keras.layers.Softmax()])</span><span id="01b5" class="mc lg ht nl b fv nt nq l nr ns">    return tff.learning.from_keras_model(<br/>        model,<br/>        loss=tf.keras.losses.SparseCategoricalCrossentropy(),<br/>        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])</span><span id="2180" class="mc lg ht nl b fv nt nq l nr ns">fl_model = create_model(3)</span><span id="2451" class="mc lg ht nl b fv nt nq l nr ns">evaluation = tff.learning.build_federated_evaluation(fl_model)</span></pre><h1 id="c9e2" class="lf lg ht bd lh li lj lk ll lm ln lo lp ji lq jj lr jl ls jm lt jo lu jp lv lw dt translated">挑战</h1><p id="89ba" class="pw-post-body-paragraph ki kj ht kk b kl lx jd kn ko ly jg kq kr lz kt ku kv ma kx ky kz mb lb lc ld hm dt translated">尽管外语有巨大的潜力，但它也不是没有挑战。FL型号要求节点之间频繁通信，导致网络吞吐量要求很高。然而，随着5G技术的最新进展及其更稳定、更快速的互联网连接，FL将变得更容易部署。</p><p id="c8f8" class="pw-post-body-paragraph ki kj ht kk b kl km jd kn ko kp jg kq kr ks kt ku kv kw kx ky kz la lb lc ld hm dt translated">此外，特定于设备的特性可能会限制来自某些设备的模型的一般化，并且可能会降低模型的下一版本的准确性。</p><h2 id="830f" class="mc lg ht bd lh md me mf ll mg mh mi lp kr mj mk lr kv ml mm lt kz mn mo lv hz dt translated">替代方案:八卦学习</h2><p id="a095" class="pw-post-body-paragraph ki kj ht kk b kl lx jd kn ko ly jg kq kr lz kt ku kv ma kx ky kz mb lb lc ld hm dt translated">在FL中，一个中央模型使用其他设备的输出来建立一个新的模型，这并不是真正完全分散的。研究人员提议使用<strong class="kk id">区块链联邦学习</strong> (BlockFL)和其他方法来建立FL的零信任模型。</p><p id="68ac" class="pw-post-body-paragraph ki kj ht kk b kl km jd kn ko kp jg kq kr ks kt ku kv kw kx ky kz la lb lc ld hm dt translated"><strong class="kk id">八卦学习</strong> (GL)已经被许多研究者提出来解决外语学习中的一些问题。GL是完全分散的，并且没有用于合并来自不同位置的输出的服务器。本地节点直接交换和聚合模型。GL的优势是显而易见的:因为不需要基础设施，也没有单点故障，GL享有显著更低的可伸缩性和更好的健壮性。</p><h1 id="397a" class="lf lg ht bd lh li lj lk ll lm ln lo lp ji lq jj lr jl ls jm lt jo lu jp lv lw dt translated">结论</h1><p id="0306" class="pw-post-body-paragraph ki kj ht kk b kl lx jd kn ko ly jg kq kr lz kt ku kv ma kx ky kz mb lb lc ld hm dt translated">区块链技术为加密货币和去中心化应用提供了基础。这些工具共同创造了一个快速增长的DeFi(去中心化金融)行业。正如DeFi可以随着这个行业的发展为企业开辟新的途径一样，联合学习可以彻底改变机器学习的世界。像任何新技术一样，FL项目最初会获得不同程度的成功。商业领袖将需要选择这些项目中的哪一个将为他们的商业增加最大的价值。</p><blockquote class="nu"><p id="94b3" class="nv nw ht bd nx ny nz oa ob oc od ld ek translated">加入Coinmonks <a class="ae kh" href="https://t.me/coincodecap" rel="noopener ugc nofollow" target="_blank">电报频道</a>和<a class="ae kh" href="https://www.youtube.com/c/coinmonks/videos" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>了解加密交易和投资</p></blockquote><h1 id="9715" class="lf lg ht bd lh li lj lk ll lm ln lo lp ji oe jj lr jl of jm lt jo og jp lv lw dt translated">另外，阅读</h1><ul class=""><li id="4397" class="mq mr ht kk b kl lx ko ly kr oh kv oi kz oj ld mv mw mx my dt translated"><a class="ae kh" href="https://coincodecap.com/ftx-futures-trading" rel="noopener ugc nofollow" target="_blank">如何在FTX交易所交易期货</a> | <a class="ae kh" href="https://coincodecap.com/okex-vs-binance" rel="noopener ugc nofollow" target="_blank"> OKEx vs币安</a></li><li id="957d" class="mq mr ht kk b kl mz ko na kr nb kv nc kz nd ld mv mw mx my dt translated"><a class="ae kh" href="https://coincodecap.com/coinloan-review" rel="noopener ugc nofollow" target="_blank"> CoinLoan审查</a> | <a class="ae kh" rel="noopener" href="/coinmonks/youhodler-4-easy-ways-to-make-money-98969b9689f2"> YouHodler审查</a> | <a class="ae kh" href="https://coincodecap.com/blockfi-review" rel="noopener ugc nofollow" target="_blank"> BlockFi审查</a></li><li id="be9f" class="mq mr ht kk b kl mz ko na kr nb kv nc kz nd ld mv mw mx my dt translated">XT.COM评论<a class="ae kh" href="https://coincodecap.com/profittradingapp-for-binance" rel="noopener ugc nofollow" target="_blank">币安评论</a> | <a class="ae kh" href="https://coincodecap.com/xt-com-review" rel="noopener ugc nofollow" target="_blank"/></li><li id="a82f" class="mq mr ht kk b kl mz ko na kr nb kv nc kz nd ld mv mw mx my dt translated"><a class="ae kh" href="https://coincodecap.com/smithbot-review" rel="noopener ugc nofollow" target="_blank"> SmithBot评论</a> | <a class="ae kh" href="https://coincodecap.com/free-open-source-trading-bots" rel="noopener ugc nofollow" target="_blank"> 4款最佳免费开源交易机器人</a></li><li id="76cd" class="mq mr ht kk b kl mz ko na kr nb kv nc kz nd ld mv mw mx my dt translated"><a class="ae kh" rel="noopener" href="/coinmonks/coinbase-bots-ac6359e897f3">比特币基地僵尸程序</a> | <a class="ae kh" rel="noopener" href="/coinmonks/ascendex-review-53e829cf75fa"> AscendEX审查</a> | <a class="ae kh" rel="noopener" href="/coinmonks/okex-trading-bots-234920f61e60"> OKEx交易僵尸程序</a></li></ul></div></div>    
</body>
</html>